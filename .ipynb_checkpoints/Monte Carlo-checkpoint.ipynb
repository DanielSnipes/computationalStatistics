{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy.random as r\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from __future__ import division\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A Simple Game**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's toss a coin ten times. How many Heads are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tosses = r.choice([\"H\",\"T\"],10)\n",
    "num_heads = Counter(tosses)[\"H\"]\n",
    "num_heads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the coin was fair we should have seen 5 right? If we see something other than 5, then something is wrong? No, of course not. \n",
    "\n",
    "We know that know that we *might* see 5 Heads, that we *ought* to see 5 heads *on average*, that we can *expect* to see 5 heads. But we know that many different outcomes are possible, only some which include exactly 5 Heads. \n",
    "\n",
    "In fact, let's see a few of those different outcomes. If we repeat this expermiment a few times, we see that lots of different outcomes are possible, and common, and expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This time we see 6 heads.\n",
      "This time we see 4 heads.\n",
      "This time we see 4 heads.\n",
      "This time we see 7 heads.\n",
      "This time we see 2 heads.\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    tosses = r.choice([\"H\",\"T\"],10)\n",
    "    print \"This time we see \" + str(Counter(tosses)[\"H\"]) + \" heads.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see quite a bit of variability between each of these different \"experiments\". Here, we did 5 experiments and saw 5 of the possible outcomes. If we do many more than 5 experiments, we can get a good and general sense of the set of all possible things we might ever expect to see from our coin tossing game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def how_many_heads(N):\n",
    "    draw = r.choice([\"H\",\"T\"],N)\n",
    "    return Counter(draw)[\"H\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lots_of_experiments =  [how_many_heads(10) for i in range(10000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes.AxesSubplot at 0xc4d68d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD/CAYAAAD2Qb01AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc4d65b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(lots_of_experiments,kde=False,rug=False,bins=len(set(lots_of_experiments)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now we see the full set of things that we could reasonably expect from our coin tossing game. We might see 8 Heads, we might see 2. Both are possible. Both are *less likely* than seeing 5, which is the *most likely* outcome. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Sampling Distribution**\n",
    "\n",
    "The histogram we made above shows us the full set (or approximately) of outcomes we might ever see from our experiment. Any one experiment we conduct in the real world is but one sample from this hypothetical pool. For each experiment, we summarized the result with a single value (the total number of Heads), let's refer to this value as a *statistic* (or *test statistic* if we want to start getting real). The histogram above shows the full distribution of the test statistic if we consider the set of all possible experiments. This distribution is called the frequentist *sampling distribution* and is at the heart of all the classical statistical methods you've learned before. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A Simple Probability Distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's come at this coin tossing game another way. The mathy way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the probability of tossing a coin once and it landing heads. For a fair coin, $p(H) =.5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's be a bit more general and consider not just a fair coin, but a coin with any possible bias. So we can characterize the coin by this amount of bias, which we'll call $\\theta$. The probability of Heads will in fact define $\\theta$, so $p(H) = \\theta$ and $p(T) = 1 - \\theta$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we toss the coin twice, what's the probability of two Heads? Well, because it's easy, let's just enumerate all the possibilities. \n",
    "\n",
    "$p(HH) = \\theta * \\theta  $\n",
    "$p(HT) = \\theta * (1 -\\theta)  $\n",
    "$p(TH) = (1 - \\theta) * \\theta  $\n",
    "$p(TT) = (1 - \\theta) * (1 - \\theta) $\n",
    "\n",
    "From the four possible outcomes, we see that there is 1 outcome with 2 Heads, 1 outcome with 2 Tails and 2 outcomes with 1 Heads. Now we can update our estimates:\n",
    "\n",
    "$p(Two Heads) = \\theta * \\theta  $\n",
    "$p(One Heads) = 2 * \\theta * (1 -\\theta)  $\n",
    "$p(Two Tails) = (1 - \\theta) * (1 - \\theta) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we as ask these same basic questions but about 3 coin tosses, or 4 coin tosses etc, a general pattern emerges. For a given number of coin tosses, the probability of the number of heads will follow what's called the *Binomial distribution*. It looks like this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p(k|N) = \\frac{N!}{k! (N-k)!}\\theta^k (1-\\theta)^{N-k}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That first part, with the factorials, just has to do with the combinatorics, the number of possible ways of acheiving a given outcome. The second part is just the product of the probabilites in the same way we did before. So if we ask \"Whats the probability of getting 3 Heads if we toss the coin 5 times\", the answer is proportional to $\\theta$ raised to the 3 times $(1-\\theta)$ raised to the 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we've done is to figure out a simple expression for the distribution of the number of Heads we might see in our experiment. We have figured out the exact form of the *sampling distribution* that we just talked about. For any question we have, for any coin tossing experiment, the answer can be found with this Binomial distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So What Is Monte Carlo?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've gotten to the samping distribution in two ways. And they are the same. Don't believe me? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[figure out how to plot the linegraph of binomial on top of histogram]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are the same (approximately) and we got them in two different ways. One by direct and  simulation, and the other by some mathematical thinking. And this is the point of Monte Carlo. We can estimate/approximate the sampling distribution by doing repeated random draws and simulations. \n",
    "\n",
    "And the two methods represent the same thing (like two side of the same coin (sorry)). The closed form expression we found is simply the direct answer to questions about what the possible outcomes are. The Monte Carlo is simply a direct simulation of what the possible outcomes are. In this case, the Binomial distribution was easy enough to figure out, but this demonstrates that if we *can't* figure out the sampling distribution analytically, it is perfectly valid to simulate it. \n",
    "\n",
    "And this points to the history of classical statistics - a time in the early 20th century way before effective computers. Mathematicians such as Fisher, Neyman, and Pearson put a lot of effort into deriving exact expressions of these \"sampling\" distributions under different assumptions. And if your data and your questions fit those assumptions then go ahead and use those classical techniques. But here we are now with fast computing machines and we can get back to the basic question behind all of this which is, \"If I did this experiment again, what would I see?\". And now, we can just simulate that question, many times, to get and understanding an context about what we measured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monte Carlo methods were first introduced in the statistical physics community in the 1950s, in a method we'll go through later relating to Bayesian statistics. But the basic premise there was, \"We're trying to study a complicated physical system (nuclear reactions) and we don't have a nice simple form for the answer we want. But we do have a big computer and access to random numbers, so we can sort of just simulate this thing over and over again and get an approximation to the question we're asking.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This, then, is the point of Monte Carlo. If we *know* the details of the process we're interested in (such as coin tossing), but we don't have the final answer to some qustion (we don't know about the binomial distribution), we can just simulate the process many times. We just need for-loops, no derivations. (As a teaser, later we'll go through Bootstrapping, a method that allows us to approximate some unknown sampling distribution, even if we know nothing about the process that generated the data.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Putting It Back Together**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go back to our coin tossing game and pretend we care really deeply about the outcomes. Maybe we're playing a gambling game with someone, there's money on the line, and we're starting to suspect they are cheating. To make things a little more interesting let's increase the size of our tossing game from 10 consecutive tosses up to 50. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we have a sneaky adversary who is tossing a rigged coin that is more likely to throw Tails than Heads. We see one outcome of this game and it looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['H', 'H', 'T', 'T', 'T', 'H', 'T', 'T', 'H', 'H', 'T', 'T', 'H',\n",
       "       'T', 'T', 'T', 'T', 'T', 'H', 'H', 'T', 'T', 'H', 'H', 'H', 'H',\n",
       "       'T', 'T', 'T', 'H', 'T', 'H', 'T', 'T', 'T', 'T', 'T', 'H', 'H',\n",
       "       'T', 'H', 'H', 'T', 'T', 'T', 'T', 'T', 'H', 'T', 'T'], \n",
       "      dtype='|S1')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamble = r.choice([\"H\",\"T\"],50, p=[.4,.6])\n",
    "gamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how many Heads we saw:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(gamble)['H']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's certainly less than the number of Heads we expect, which should be 25. But how much less? It it worrisome? Maybe it just happened that why by chance, we don't want to make false accusations and get kicked out of this casino. Well, the sampling distribution is exactly the quantification of all of this uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's use Monte Carlo methods to simulate the sampling distribution of this game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "approx_sampling_distribution =  [how_many_heads(50) for i in range(25000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we simply need to ask, \"How many of the possible outcomes have fewer Heads that the particular outcome I saw?\". Simple enough in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03376"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([outcome < Counter(gamble)['H'] for outcome in approx_sampling_distribution]) / len(approx_sampling_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's probability that we got that particular draw from a fair coin, pretty unlikely indeed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, we can ask this question more visually.... [Figure]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you didn't notice, we're dancing right up to next to notions such as hypothesis testing and p-values. Our null hypothesis is that the coin is fair, and so we simulated its sampling distribution. We then asked where our observed outcome lies with respect to that expected sampling distribution. We then asked what's the probability that an outcome from the null sampling distribution is *more extreme* that the outcome we actually observed. That's a p-value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for the sake of completeness, let's compare with the analytical answer. From the binomial distribution, we know we can calculate the probability of seeing $k$ Heads given 50 tosses. We simply need to sum up this probability for all the $k$ less than the number of Heads we observed. And we see that our simulated sampling was quite close, and can in fact be made arbitrarily accurate with more samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Another Example**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point here is that whatever complex thing we're thinking about, whether it's coins and dice, or particle physics, or the stock market, we can pretty easily write a for-loop to get a sense of the *most probable* outcomes of that process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a classic one you may have done before - estimating the value of Pi with random numbers. This one isn't solving a stastics problem per say, but is solving a calculus problem, though we wouldn't typically think of it that way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the trick - image  the unit circle inscribed inside the unit square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[put a picture]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know the area of the unit square is 1x1=1 and the area of the unit circle is pi x r^2 = pi. So this pi thing, what is its numeric value? For simplicity, consider just the upper right quadrant of the unit square, so we now have an arc of the circle that has one quarter the area of the entire circle, so it has area pi/4.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed by throwing darts. Imagine this quarter-cirlce in a square is a dart board. If we throw a dart such that is does land somewhere inside the square board (we're at least decent at darts), what's the probability that it lands within the arc? No trick question here to this simple geometric probability puzzle. It's simply equal to the proportion of the area that the circle occupies relative to the total area of the square. So in this case, the probability is pi/4 / 1x1, so it's just the area of the square. (As I alluded, you can view this probability puzzle as a calculus problem, where we need to evaluate the ratio of two integrals.)\n",
    "\n",
    "So given that we *expect* a random dart to land within the arc with probability pi/4, we can throw a *huge number* of random darts at this board and simply count the fraction that land within the arc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dart_location():\n",
    "    '''\n",
    "    Throw a dart, where does it land\n",
    "    '''\n",
    "    x = r.rand()\n",
    "    y = r.rand()\n",
    "    return (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def magnitude(tuple2):\n",
    "    '''\n",
    "    Good ol' Pythagoras\n",
    "    '''\n",
    "    return np.sqrt(tuple2[0]**2+tuple2[1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141664"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_darts = 1000000\n",
    "arc = sum([magnitude(dart_location()) < 1 for i in range(num_darts)]) / num_darts\n",
    "arc * 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this was just another example of how something that might be a really hard problem (calculating some integrals) can be approximated with clever use of random numbers. And note the relationship between integration of a function and the limiting properties of random samples drawn from a probability distribution\n",
    "\n",
    "$ \\int f(x) dx \\approx \\frac{1}{N} \\sum_{i=1}^N x_i where x_i \\sim f(x) $\n",
    "\n",
    "This is a general idea called Monte Carlo Integration and it will come back with ferocity when we discuss MCMC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Next **\n",
    "\n",
    "[Need one more example in hypothesis testing or something statistical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
